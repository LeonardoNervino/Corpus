# -*- coding: utf-8 -*-
"""Trabalho4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wfYnI4VCDz7bv6hx5qcReVY_HfIH0hk5
"""

'''   Aluno: Leonardo Nervino Friedrich

Sua  tarefa  será  transformar  um  conjunto  de  5  sites,  sobre  o  tema  de  processamento  de 
linguagem natural em um conjunto de cinco listas distintas de sentenças. Ou seja, você fará uma função 
que, usando a biblioteca Beautifull Soap, faça a requisição de uma url, e extrai todas as sentenças desta 
url. Duas condições são importantes:  
a) A página web (url) deve apontar para uma página web em inglês contendo, não menos que 
1000 palavras.  
b) O texto desta página deverá ser transformado em um array de senteças.'''

import requests
from bs4 import BeautifulSoup

html1 = requests.get('https://www.wonderflow.ai/blog/natural-language-processing-examples')

site1 = BeautifulSoup(html1.text, "html.parser")
termosite1 = []

html2 = requests.get('https://www.cio.com/article/228501/natural-language-processing-nlp-explained.html')

site2 = BeautifulSoup(html2.text, "html.parser")
termosite2 = []

html3 = requests.get('https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP')

site3 = BeautifulSoup(html3.text, "html.parser")
termosite3 = []

html4 = requests.get('https://machinelearningmastery.com/natural-language-processing/')

site4 = BeautifulSoup(html4.text, "html.parser")
termosite4 = []

html5 = requests.get('https://www.ibm.com/cloud/learn/natural-language-processing')

site5 = BeautifulSoup(html5.text, "html.parser")
termosite5 = []


print('1º HTML:')

for html1 in site1.find_all("p"):
    termosite1.append(html1.get_text())

print(termosite1)
print("*****************************************************************")

print('2º HTML:')

for html2 in site2.find_all("p"):
    termosite2.append(html2.get_text())

print(termosite2)
print("*****************************************************************")

print('3º HTML:')

for html3 in site3.find_all("p"):
    termosite3.append(html3.get_text())

print(termosite3)
print("*****************************************************************")

print('4º HTML:')

for html4 in site4.find_all("p"):
    termosite4.append(html4.get_text())

print(termosite4)
print("*****************************************************************")

print('5º HTML:')

for html5 in site5.find_all("p"):
    termosite5.append(html5.get_text())

print(termosite5)